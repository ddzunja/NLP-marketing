{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models import LdaModel\n",
    "from gensim import corpora\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "# from hunspell import HunSpell\n",
    "from multiprocessing import pool\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 391/10000 [00:00<00:02, 3902.08it/s]\u001b[A\n",
      "  9%|▊         | 861/10000 [00:00<00:02, 4111.20it/s]\u001b[A\n",
      " 13%|█▎        | 1289/10000 [00:00<00:02, 4158.31it/s]\u001b[A\n",
      " 16%|█▋        | 1633/10000 [00:00<00:02, 3912.03it/s]\u001b[A\n",
      " 20%|██        | 2031/10000 [00:00<00:02, 3928.85it/s]\u001b[A\n",
      " 24%|██▎       | 2374/10000 [00:00<00:02, 3763.90it/s]\u001b[A\n",
      " 28%|██▊       | 2772/10000 [00:00<00:01, 3819.59it/s]\u001b[A\n",
      " 32%|███▏      | 3154/10000 [00:00<00:01, 3804.23it/s]\u001b[A\n",
      " 36%|███▌      | 3552/10000 [00:00<00:01, 3854.24it/s]\u001b[A\n",
      " 39%|███▉      | 3924/10000 [00:01<00:01, 3785.32it/s]\u001b[A\n",
      " 43%|████▎     | 4345/10000 [00:01<00:01, 3903.12it/s]\u001b[A\n",
      " 47%|████▋     | 4730/10000 [00:01<00:01, 3869.94it/s]\u001b[A\n",
      " 51%|█████     | 5113/10000 [00:01<00:01, 3831.68it/s]\u001b[A\n",
      " 55%|█████▍    | 5494/10000 [00:01<00:01, 3816.31it/s]\u001b[A\n",
      " 59%|█████▉    | 5922/10000 [00:01<00:01, 3943.63it/s]\u001b[A\n",
      " 63%|██████▎   | 6317/10000 [00:01<00:00, 3917.03it/s]\u001b[A\n",
      " 67%|██████▋   | 6718/10000 [00:01<00:00, 3942.45it/s]\u001b[A\n",
      " 71%|███████▏  | 7149/10000 [00:01<00:00, 4042.40it/s]\u001b[A\n",
      " 76%|███████▌  | 7554/10000 [00:01<00:00, 4043.61it/s]\u001b[A\n",
      " 80%|████████  | 8001/10000 [00:02<00:00, 4159.89it/s]\u001b[A\n",
      " 85%|████████▍ | 8451/10000 [00:02<00:00, 4254.91it/s]\u001b[A\n",
      " 89%|████████▉ | 8878/10000 [00:02<00:00, 4126.35it/s]\u001b[A\n",
      " 93%|█████████▎| 9293/10000 [00:02<00:00, 4033.12it/s]\u001b[A\n",
      " 97%|█████████▋| 9699/10000 [00:02<00:00, 3964.25it/s]\u001b[A\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 3977.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Words In Comments: 34550\n",
      "Documents/Comments: 10000\n"
     ]
    }
   ],
   "source": [
    "df = getDF('data/reviews/reviews_Musical_Instruments.json.gz')\n",
    "\n",
    "ans = df.reviewText + ' ' + df.summary\n",
    "\n",
    "n = 10000\n",
    "re_punctuation = re.compile('['+string.punctuation+']')\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "stop = stopwords.words('english')\n",
    "preprocessed_comments = []\n",
    "for comment in tqdm(np.random.choice(ans, n)):\n",
    "    comment = re_punctuation.sub(' ', comment)\n",
    "    comment = tokenizer.tokenize(comment)\n",
    "    comment = [x for x in comment if not any(c.isdigit() for c in x)]\n",
    "    ########### HERE You have to insert HunSpell\n",
    "    comment = [word for word in comment if word not in stop]\n",
    "    preprocessed_comments.append(comment)\n",
    "    \n",
    "    \n",
    "wordFrequency = Counter()\n",
    "for comment in preprocessed_comments:\n",
    "    wordFrequency.update(comment)                                  # Count overall word frequency\n",
    "print('Unique Words In Comments: {}'.format(len(wordFrequency)))\n",
    "\n",
    "minimumWordOccurrences = 5\n",
    "# Remove rare words\n",
    "texts = [[word for word in comment if wordFrequency[word] > minimumWordOccurrences] for comment in preprocessed_comments]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)                             # Create word dictionary\n",
    "vocabulary = [dictionary[i] for i in dictionary.keys()]\n",
    "print('Documents/Comments: {}'.format(len(texts)))\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in preprocessed_comments]                # Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:09<01:24,  9.41s/it]\u001b[A\n",
      " 20%|██        | 2/10 [00:18<01:13,  9.21s/it]\u001b[A\n",
      " 30%|███       | 3/10 [00:28<01:06,  9.53s/it]\u001b[A\n",
      " 40%|████      | 4/10 [00:39<00:59,  9.91s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [00:50<00:51, 10.20s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [01:00<00:41, 10.36s/it]\u001b[A\n",
      " 70%|███████   | 7/10 [01:11<00:31, 10.50s/it]\u001b[A\n",
      " 80%|████████  | 8/10 [01:22<00:21, 10.55s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [01:33<00:10, 10.64s/it]\u001b[A\n",
      "100%|██████████| 10/10 [01:43<00:00, 10.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: perfect hard found always item record others received original collection\n",
      "Topic 2: Not full hear speaker fun volume performance Love speakers wood\n",
      "Topic 3: works mic recording cable unit software USB worked perfectly plug\n",
      "Topic 4: pedal violin clean beginner ones reason rest learn board video\n",
      "Topic 5: The two work many one There first power less also\n",
      "Topic 6: sound like really little better much good It sounds even\n",
      "Topic 7: high low guitars top side solid Fender bridge All finish\n",
      "Topic 8: keyboard drum Excellent days value change nothing kit next seem\n",
      "Topic 9: They small These Amazon We tried big system read simple\n",
      "Topic 10: set live band A built studio room mics times level\n",
      "Topic 11: great It This price well quality good Great product nice\n",
      "Topic 12: I one would time get bought case used could got\n",
      "Topic 13: music piano CD album songs song recording heard track enjoy\n",
      "Topic 14: guitar amp playing instrument play tone string end neck size\n",
      "Topic 15: strings love He beautiful player stage drums friend choice jazz\n",
      "Topic 16: box came three shipping inside stands bottom wish hole uke\n",
      "Topic 17: thing You bit But long though going problem every last\n",
      "Topic 18: use stand easy need want enough If make fine without\n",
      "Topic 19: new back go worth tune tuner bag ordered tuning day\n",
      "Topic 20: plastic After NOT On pair four hardware liked glad everyone\n"
     ]
    }
   ],
   "source": [
    "numberTopics = 20   #Number of topics\n",
    "\n",
    "model_gensim = LdaModel(num_topics=numberTopics,\n",
    "                        id2word=dictionary,\n",
    "                        iterations=10,\n",
    "                        passes=1,\n",
    "                        chunksize=50,\n",
    "                        alpha='auto',\n",
    "                        eta='auto',\n",
    "                        update_every=1)\n",
    "\n",
    "\n",
    "perp_gensim = []\n",
    "times_gensim = []\n",
    "i=0\n",
    "max_it = 5\n",
    "min_prep = np.inf\n",
    "start = time()\n",
    "\n",
    "for _ in tqdm(range(100)):\n",
    "    model_gensim.update(corpus)\n",
    "    tmp = np.exp(-1 * model_gensim.log_perplexity(corpus))\n",
    "    perp_gensim.append(tmp)\n",
    "    times_gensim.append(time() - start)\n",
    "    if(tmp<min_prep):\n",
    "        min_prep = tmp;\n",
    "    else:\n",
    "        i = i + 1;\n",
    "        if (i==max_it):\n",
    "            break                # if prep increase for max_it number it will break the update procedure \n",
    "for i, topic in enumerate(model_gensim.get_topics().argsort(axis=1)[:, -10:][:, ::-1], 1):\n",
    "    print('Topic {}: {}'.format(i, ' '.join([vocabulary[id] for id in topic])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
